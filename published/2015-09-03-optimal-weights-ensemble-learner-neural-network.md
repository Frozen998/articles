#运用神经网络方法找寻集成学习中的最优权重

##简介

众所周知，如今在众多数据科学竞赛中的获奖方案中，使用集成学习算法已然成为了家常便饭。集成学习独有的依据一系列假设对大量机器学习算法进行训练的能力，不仅增加了模型的稳定性，同时也使得模型的精确程度得到了较高的提升。在此之前，如果你对集成学习还是没有什么印象的话，之前推送的文章《关于集成学习基础的简单描述》或许会对你有所帮助。

话说回来，在构建集成模型时，如何找到最佳的权重往往是人们面临的常见挑战之一。说实话，并没有多少人会去真正直面这样的挑战，那些勇气不足的数据工作者们经常会说服自己去使用简单的套袋方法，也就是赋予所有学习算法相同的权重，并将平均预测值作为模型的最终结果。

这么做的效果通常来说也很不错，因为等权平均的方法同样能够减少单个模型所带来的方差。然而，我们都知道，分配相等的权重往往并不是获得最佳模型组合的最好方法，那么问题就来了，我们到底该怎么做？在本文中，我们将基于R语言中的神经网络相关功能，为您找到在集成模型中确定最佳权重的可行方法。

![](http://static.datartisan.com/upload/attachment/2015/09/kBKQRx4P.jpg)

#先来考虑一个简单的问题

现在我们假设你已经基于一个给定的（假想的）数据集构建了三个模型，每一个模型都具有预测目标事件发生概率的能力。在下图中：Model 1, Model 2和Model 3分别表示我们构建的三个预测模型，它们各有所长，但“团队合作”将会更好地优化它们的预测表现。

![](http://static.datartisan.com/upload/attachment/2015/09/BMGoyN23.png)

我们之前的假设是赋予每个模型33.33%的权重，并由此构建一个集成模型。而在这里，我们面临的挑战将是最优化模型的权重w1,w2和w3，从而建立一个更加高效强大的集成模型。



#解决这一问题的传统途径是什么？

假设P1，P2和P3为三个模型的三个输出。我们需要以最优化目标函数的形式来得到最优化的W1，W2和W3。让我们试着用数理的方法来表示约束和目标函数：

约束：
```

w1 + w2 + w3 = 1

p = w1 * p1 + w2 * p2 + w3 * p3
```

目标函数（极大似然函数）：

```
Maximize ([ (p) ^ (y) * (1-p) ^ (1-y) ]对于所有观测样本的乘积)
```

```
其中，
y：观测的目标反应
p：通过集成模型得到的预测概率
p1,p2,p3 : 单个模型得到的预测概率 
w1,w2,w3 : 各个模型所对应的权重
```
上述的是一个经典的纯优化方法。然而，当我们需要对大量模型进行套袋，并且每次都用数学公式来对它进行表达与运算时，往往会导致巨大的工作压力和时间上的消耗。因此，我们需要一个更聪明的方法。

接下来，我们将尝试着改变一下确定这些权重的方式，运用神经网络方法而非那些繁琐的数学公式。



##如何运用神经网络来实现权重的最优化？

我明白，要完全弄懂神经网络的实施原理有时会很复杂。因此，为了解决本文中迫在眉睫的问题，我们不会去深入钻研深层神经网络的那些复杂概念。

从最基本的方面来说，神经网络方法就是在寻找相邻点之间的权重（输入变量到隐藏节点和隐藏节点到输出节点）。而此时，我们的目标则是要找到从输入节点直接到输出节点的正确权重组合，这似乎和神经网络的初衷不太一样。

我们用一个简单但是实用的方法来解决这个问题：我们将神经网络中隐藏节点的个数限制为1，这将使得隐藏节点到输出节点的权重被自动调整为1。这也意味着，神经网络中的隐藏节点和输出节点不再是不同的，如下图所示：

![](http://static.datartisan.com/upload/attachment/2015/09/ZCm7v4pj.png)

就这样，我们找到了一个方法——借助计算机编程，需要我们进行大量人工计算的数学方程将由计算机自动完成，相关的R代码如下：

```
#x is a matrix of multiple predictions coming from different learners
#y is a vector of all output flags 
#x_test is a matrix of multiple predictions on an unseen sample
x <- as.matrix(prediction_table)
y <- as.numeric(output_flags)
nn <- dbn.dnn.train(x,y,hidden = c(1), activationfun = "sigm",learningrate = 0.2,momentum = 0.8)
nn_predict <- n.predict(nn,x)
nn_predict_test <- n.predict(nn,x_test)
```

##结束语

笔者曾经将上述最优权重确定的逻辑运用到Kaggle数据建模竞赛中的很多问题里，并且得到了一系列令人欣喜的好结果，下列是在近期竞赛中的该方法获得的成绩：简易逻辑模型的评分为100，最佳机器学习模型的评分为107，简易套袋技术最终获得了110的评分，而利用神经网络优化模型权重则得到了113的高分。

在这篇文章中，笔者解释了在集合模型中找到最佳的权重的方法，传统的方法很经典，但更受推荐的无疑还是神经网络，希望这对你有所帮助。



原文作者： TAVISH SRIVASTAVA

翻译：SDCry!!

原文链接：http://www.analyticsvidhya.com/blog/2015/08/optimal-weights-ensemble-learner-neural-network/
