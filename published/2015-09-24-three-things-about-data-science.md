#书本不会告诉你，数据科学三件事

可能你还不知道，数据科学是时下的热门。数据科学的课程、文章和学校遍地开花。但它们总在强调算法学习。的确，理解罗吉斯回归或深度学习的原理很棒。但当你开始做数据工作，就会发现还有更重要的事。

我无法责备这些（强调算法）课程。我在大学教授多年机器学习，课堂上总是强调具体算法。学生会学习关于支持向量机、高斯混合模型、K-means聚类等等算法的方方面面。但直到写硕士论文时，学生才能了解如何适当地做数据工作。

“适当地”是什么意思？ 为达目标不是可以使用任何方法吗？只要预测表现良好不就万事大吉了吗？这当然没错，但问题关键是确保 “未来数据”表现良好。正如我在其他文章写过的一样，如果只看训练数据，就相信你的模型运行良好，这只是自欺欺人。

所以在本文，我将给出三个书本上没有的见解。

![](http://static.datartisan.com/upload/attachment/2015/09/MIo0SKby.jpg)

##1.评估是关键

数据分析/机器学习/数据科学（不管你怎么称呼）的主要目的是建立一个能在未来数据上表现良好的系统。考虑到监督学习（如分类）和无监督学习（如聚类）的差别，很难统一概括上面这句话的意义，但不管怎样，你通常都是收集数据集，并建立、设计模型。最终你会想要把模型应用于未来的数据，你会想要确保模型运行良好，并且输出同你在原始数据集里一样好的结果。

初学者常犯的一个错误是只看模型在当前的数据集上的表现。之后便认定模型会在未来数据上有效。遗憾的是事实很少如此。这里我们只谈论监督学习，即基于输入预测输出，例如，分类正常邮件和垃圾邮件。

如果只考虑训练数据，机器很容易通过记忆一切来做出完美预测（除非数据本身自相矛盾）。类比人类，你在背外语单词时，不得不打乱顺序来做测试，否则大脑仅仅会按顺序逐个记住单词。机器拥有储存和提取大量数据的强大能力，让他们轻易实现类似的结果。这会导致过度拟合，缺乏泛化能力。

所以，正确的方法是模拟未来的数据，把原始的数据分割，一部分用来训练，一部分用来预测。通常训练集要大一些。整个过程要循环几次，以得到一些数字来了解模型的稳定程度。这个过程叫做交叉验证。

![](http://static.datartisan.com/upload/attachment/2015/09/Y9sGO1Ao.png)

 * 图1.为了模拟未来数据的表现, 把当前数据分为两部分，一部分用来训练，一部分用来测试。



即使如此，差错仍时常发生，尤其当数据是非静态的时候，非静态意味着数据的潜在分布随时间变化。在你观察测量真实世界的数据时，这种情况时常发生。一月份的销售数据看起来和六月份的迥然不同。

或者数据间有许多关联，这意味着获知了一个数据样本，另一个也就八九不离十了。例如，股票价格在两天之间通常不会有巨大跳跃，所以通过日期划分训练集和测试集会导致他们之间高度相关。

上述情况一旦发生，你就会获得过度优化结果。而模型在测试数据上的表现将不尽如人意。最糟糕的情况是，你终于说服人们在实践中尝试你的模型，模型却不灵了。所以学习如何适当地评估是关键。



##2.特征提取是一切

学习一种新模型令人兴奋。但事实是复杂模型表现都大同小异。真正的差别在于在学习过程中从原始数据提取特征的方法。

现代的学习模型很是强大，可以轻易处理上万特征和几十万样本。但这些模型事实上很愚钝。尤其是那些线性模型（如罗吉斯回归或线性支持向量机），像计算器一样简陋。

这些模型善于在有充足数据的前提下，识别包含有用信息的特征。但如果没有有效信息，或输入特征的线性组合无法表示有用信息，这些模型就无能为力了。它们也无法通过“洞察”来归约数据。

换句话说，你可以通过找出这些特征来大幅度归约数据。假设你把所有特征归约为想预测的函数，那也就没什么需要学习的了，对吧？这就是特征提取的强大之处！

具体而言，这意味着两件事：首先，应该确保掌握那些近乎雷同的方法之中的一种，之后就可以维持现状。你并不真正需要罗吉斯回归加上线性支持向量机，只需要选择其一。深度学习稍微与众不同，但那些线性模型的解释力大同小异。当然，训练时间、解的稀疏性等等可能不同，但多数情况下你会得到相同的预测表现。

其次，应该详尽学习“特征工程学”。遗憾的是，它更像是一门艺术，而且因为相关理论很少，所以几乎不会在教科书中出现。标准化会很有用。有时也会需要求特征的对数。只要你能消除一些自由度，即，摆脱一些与预测任务无关的内容，你就大大减少了你要训练的数据。

这些内容有时很明显。例如，手写笔迹识别中，很明显字的颜色无关紧要，只要有前景和背景。

教科书经常推销一些看似强大的方法/模型，你只要把数据丢过去，它们会完成余下的工作。在理论角度和数据无穷的情况下，这也许是正确的。但在现实中，数据有限，我们的时间有限，找到包含有用信息的特征至关重要。



##3.最消耗时间的不是数据集规模，而是模型选择过程

多数的数据可以毫无问题地在你的内存中运行。在大数据时代，这是件你大肆张扬的事。而且模型在数据上运行很可能不会花费太多时间。但大量时间会花在从原始数据中提取特征，以及进行交叉检验，比较不同的特征提取管道以及学习模型的参数。

![](http://static.datartisan.com/upload/attachment/2015/09/pzxjSMY9.png)

 * 图2.尝试许多参数组合，基于相同数据评估表现以进行模型选择。



问题在于组合数量的井喷。假设你只有两个参数，基于数据集训练模型和得到表现预估（适当地评估，如上文解释）需要一分钟左右。若每个变量有五个候选参数值，则进行五倍的交叉检测（把数据集分成五份运行五次，每次重复使用不同的部分），这意味着为了检测模型是否运行良好，会运行125次。你会等待两小时，而非一分钟。

这里的好消息是这个过程可以轻易并行，因为运行过程是彼此完全独立的。对于常要对不同数据集独立进行相同运算（解析，提取，转换等等）的特征提取也是如此，这导致了所谓“尴尬的并行”（是的，这是个科技术语）。

坏消息则大多是对于那些“大数据工作者”而言。因为这意味着对于复杂模型可扩展实现的需求很少，而对在内存中的数据并行使用相同的特定算法，在多数情况下非常有用。

当然，类似“广告优化的TB级日志数据全球模型”或“百万用户推荐”的应用也存在着。但基本的应用案例大都是上面提及的这种情况。

最后，拥有许多数据也不意味着你需要全部数据。问题更多在于学习问题的复杂程度。如果简单的模型就能解决问题，则无需太多数据取推导模型的参数。在这种情况，选择一个随机数据集即有所帮助。如同上面提到的，有时正确的特征表示可以大幅减少所需的样本数量。



##总结

总之，理解如何适当地进行评估，能有助于减少模型不能在未来数据得到理想表现的风险。正确地特征提取可能是获得好结果的最佳工具。最后，不是总有“大数据”，虽然分布式计算有助于减少训练时间。



原文作者：Mikio L. Braun 

翻译：王鹏宇

原文链接：http://blog.mikiobraun.de/2015/03/three-things-about-data-science.html
