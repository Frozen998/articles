#关于集成学习基础的简单描述
##什么是集成学习？

集成建模是优化模型表现的一条重要途径。通常来说，将集成学习方法运用在你所构建的诸多模型之上是十分值得的，而同道中人们也一次又一次地证明着这一点。他们在诸如Kaggle之类的数据建模竞赛中往往会不约而同地采用集成学习，并且从中受益。

集成学习其实是一个很宽泛的概念，对于它的定义，可谓仁者见仁智者见智。接下来，本文将介绍一些集成建模的基本概念和思想，这些知识应该足以让你起步，从而去构建你自己的集成模型。同时，和往常一样，我们将尽量让它们看起来简单一些。

首先，让我们以一个例子来快速了解一下集成学习的基础知识。这个例子将告诉我们，其实我们几乎每天都会进行集成建模，只是我们中的大多数都还没有意识到它。

例如：我想投资XYZ公司，然而我本人并不是很清楚它的业绩究竟如何。所以我打算看看这个公司的股票价格年增长率会不会超过6%，为了得到结论，我决定去请教不同领域与层次的人士：

XYZ公司的一名员工：这个人知道公司内部的运作机制，并且掌握着一些和公司运作机制有关的内幕信息。但他对公司面临外部竞争与行业创新了解甚少，也不知道技术进步会对XYZ公司的产品演变带来怎样的影响。根据历史经验，他的判断有70%的正确率。
XYZ公司的财务顾问：这个人对企业在市场中的整体竞争策略有着长足的观察与了解。然而，他并不是很清楚公司的对内政策具体如何协调。根据历史经验，他的判断有75%的正确率。
一名股票交易员：这个人对XYZ公司的股票有着长达三年的观测经验，他对股价变动的季节性趋势以及整体市场的表现有着较深的了解。与此同时，此人对于股价的变动信息的反应也较为敏感。根据历史经验，他的判断也有70%的正确率。
XYZ公司竞争对手的一名员工：这个人知道竞争对手的内部运行机制也就是说他可能知道一些对于XYZ公司即将发生的冲击。但他却并不了解那些影响双方公司发展的主导因素。根据历史经验，他的判断只有60%的正确率。
属于同一部类的一个市场研究团队：该团队对XYZ公司产品的顾客表现进行了横向对比与变化趋势分析，但由于只专注于对顾客一方面的分析，这个团队并不清楚XYZ公司本身可能进行的一些变革。根据历史经验，他们的判断有75%的正确率。
一名社交媒体专家：这个人可以帮助我们了解XYZ公司的产品市场定位以及顾客情绪的变化趋势，但他对数据化营销以外的诸多细节并不了解。根据历史经验，他的判断有65%的正确率。
上述便是我们拥有的所有咨询渠道，我们可能会想到把这些信息进行整合，以作出一个明智的决定。

假设所有的预测是相互独立的，那么现在，当6名“专家”一致认为投资XYZ公司是一个好决定时，这项决定的联合准确率为

1 - 30%*25%*30%*40%*25%*35%

= 1 - 0.07875 = 99.92125%

假设：我们所做的预测之间相互独立的假设也许有些极端，因为人们所做的预测往往或多或少有所联系。尽管如此，我们可以看到，当我们把诸多预测联合起来的时候，我们可以变得如此的肯定。

接下来让我们稍微改变一下这种设定。这一次我们拥有6位“专家”，他们都是在同一部门工作的XYZ公司员工，而他们中的每一个人都有70%的概率会对我的投资作出正确的评判。

那么现在，如果把这些“专家”的建议结合起来，我还能将我决策的置信水平提高到99%以上吗？

显然不能，因为他们所做的预测都是基于非常相似的信息。这些员工们的预测肯定都会受到类似信息的影响，他们给出建议之间的差异最多来自于他们对公司的个人意见和在公司搜集的一些小道消息。



##集成学习到底在集成什么？

所谓集成，是将多种类型学习算法（独立模型）进行合并，以达到提升模型稳定性和预测能力的一门学问。在上面的例子中，我们把所有专家的预测结合起来的方式也可以被称作一种集成学习。

在这篇文章中，我们将讨论一些在业界广泛使用的集成技术。在谈论技术之前，先让我们了解一下我们是如何构建这么多的学习算法的。从基于的总体到构建模型的方法，模型之间的差异可以来自于各种各样的原因。

以下给出了导致模型差异的四个原因，下列因素的相互组合导致了模型们的天差地别：

###1.研究总体不同
![](http://static.datartisan.com/upload/attachment/2015/08/OLhsIJSW.jpg)
###2.模型假设不同
![](http://static.datartisan.com/upload/attachment/2015/08/lVvhyLmM.jpg)
###3.建模技术不同
![](http://static.datartisan.com/upload/attachment/2015/08/mC0tdii5.jpg)
###4.初始种子不同
![](http://static.datartisan.com/upload/attachment/2015/08/8EmaZk4i.jpg)

##集成学习中的误差（方差与偏误）
任何模型中出现的误差都可以被数理拆解为三个要素，如下所示：
![](http://static.datartisan.com/upload/attachment/2015/08/Wb6I0AHP.png)

这个式子对于下文极其重要，要了解集成模型背后的奥秘，我们首先得搞明白致使模型产生误差的原因。接下来我们将对这些误差进行简要介绍，并在这方面对每个集成学习算法进行了解。

偏误（Bias error）被用来量化预测值与实际值之间差异的均值，高偏误的出现意味着我们的模型可能遗漏了重要的变化趋势，也就是说这个模型的表现并不乐观。

方差（Variance）则是对同个体预测结果离散程度的量化，一个拥有过大方差的模型将会对你的训练总体进行过度地拟合，从而无法保证对训练集外的个体进行准确的预测。下面的图也许会让你对这一点更加明白（图中红色区域为真实值，蓝点则为预测值）：

![](http://static.datartisan.com/upload/attachment/2015/08/6UBxj3Rg.png)

-图片来源：Scott Fortman

通常情况下，当你增加模型的复杂性时，你会发现偏误的降低将直接导致模型总误差的减少，但当过了某个特定的点之后，再增加模型的复杂程度则会适得其反。最终，你的模型将面临过度拟合的问题，并且具有了较高的方差。
理论上，最优的模型应该做到尽量保持上述两类误差之间平衡，这被称为偏误与方差之间的权衡管理，而集成学习也正是执行这种权衡的方法之一。

![](http://static.datartisan.com/upload/attachment/2015/08/Ugj1NJBn.png)

-图片来源：Scott Fortman

##一些常用的集成学习技术
1.套袋（Bagging）：套袋技术指在小样本总体中多次实施类似的学习算法，最终取其预测结果的平均值作为输出。在广义的套袋算法中，你甚至可以对不同的总体使用不同的学习算法。正如你所期望的，这有助于我们减少方差错误。

![](http://static.datartisan.com/upload/attachment/2015/08/vuq4Hbif.png)

2.Boosting: Boosting是一种迭代算法，它能根据最后一个分类的预测情况来调整观测值的权重。如果一个观测值的分类被预测错误，那么该算法将会增加这个观测值的权重，否则反之。通常情况下，Boosting能有效减少偏误并构建出有效的预测模型，然而它也同时面临着过度拟合的风险。

![](http://static.datartisan.com/upload/attachment/2015/08/5jUtwL5A.png)

3.Stacking: 这是一种很有趣的模型合并方式，在这个算法中，我们往往采用一种学习算法来对其他学习算法产生的结果进行整合，而偏误或方差的减少程度则直接取决于我们所用于合并的学习算法。

![](http://static.datartisan.com/upload/attachment/2015/08/sXxmC3Ea.png)



结束语

众所周知，集成技术可以被应用于每届Kaggle预测模型建模大赛的问题里，而如何选择正确的集成学习方式有时甚至超越了科学本身，更像是一门艺术而非技术。通过经验的积累，也许在不远的将来，人们将会在机器学习的研究中找到一个诀窍，来应对不同场合中集成学习方法的选择。



原文作者： TAVISH SRIVASTAVA

翻译：SDCry!!

原文链接：http://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/


